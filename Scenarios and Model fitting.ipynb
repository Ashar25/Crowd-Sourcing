{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df081b7c",
   "metadata": {},
   "source": [
    "# Error Generation and Model fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f107f4",
   "metadata": {},
   "source": [
    "This code will add errors to the output of Data Generation.ipynb and iteratively create scenarios, perform model fitting and performance evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcb002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "crowd_data = pd.read_excel(r'crowd/24_person_grid.xlsx')\n",
    "crowd_data = crowd_data.iloc[:,1:]\n",
    "df = crowd_data.iloc[:,[1,2,5,6]]\n",
    "df_cols = list(df.columns)\n",
    "df_l =[]     #### global library\n",
    "scenario = {'Intensity':[0] , 'Duration':[1], 'Inten_Dur':[0,1]} ### Scenarios for misclassification\n",
    "dlist = [1,2,3]\n",
    "per_error = [0,10,20,30]\n",
    "classifier = ['RandomForestClassifier','LogisticRegression']\n",
    "# classifier = ['RandomForestClassifier']\n",
    "for err in per_error:\n",
    "    index = np.random.randint(0 , df.shape[0] , size = round(err*df.shape[0]/100))\n",
    "    for scene in scenario.keys():\n",
    "        df_err = df.values\n",
    "        for j in range (len(scenario[scene])):\n",
    "            y = scenario[scene]\n",
    "            for i in index:\n",
    "                if df_err[i,y[j]] == 1:\n",
    "                    dlist.remove(1)\n",
    "                    df_err[i,y[j]] = random.choice(dlist)\n",
    "                elif df_err[i,y[j]] == 2:\n",
    "                    dlist.remove(2)\n",
    "                    df_err[i,y[j]] = random.choice(dlist)\n",
    "                else:\n",
    "                    dlist.remove(3)\n",
    "                    df_err[i,y[j]] = random.choice(dlist)\n",
    "                dlist = [1,2,3]\n",
    "        features = df_err[:,0:3]\n",
    "        target   = df_err[:,3]\n",
    "        X_train,X_test,Y_train,Y_test = train_test_split(features, target, test_size = 0.3,random_state =42)\n",
    "        for clf in classifier:\n",
    "            sub_list = []\n",
    "            if clf =='RandomForestClassifier':\n",
    "                clf_p = eval(clf)(criterion='gini',random_state = 0)\n",
    "            elif clf =='LogisticRegression':\n",
    "                clf_p = eval(clf)(multi_class = 'multinomial',random_state = 0,max_iter=1000)\n",
    "            else:\n",
    "                clf_p = eval(clf)(random_state=42)\n",
    "            clf_p.fit(X_train,Y_train)\n",
    "            Y_train_predict,Y_test_predict = clf_p.predict(X_train),clf_p.predict(X_test)\n",
    "            conf_matrix = confusion_matrix(Y_test_predict, Y_test)\n",
    "            scores = cross_val_score(clf_p, X_train, Y_train, cv = 3, scoring='accuracy')\n",
    "            print(f'Cross val accuracy for {clf} = ', scores.mean()*100,'%')\n",
    "#             sns.heatmap(conf_matrix)\n",
    "            #print(conf_matrix)\n",
    "            conf_mat1,conf_mat2,conf_mat3   = np.zeros((2,2)),np.zeros((2,2)),np.zeros((2,2))\n",
    "            conf_mat1[0,0],conf_mat1[0,1],conf_mat1[1,0],conf_mat1[1,1] = conf_matrix[0,0],conf_matrix[0,1]+conf_matrix[0,2],\\\n",
    "                                                           conf_matrix[1,0]+conf_matrix[2,0],conf_matrix[1,1]+\\\n",
    "                                                           conf_matrix[1,2]+conf_matrix[2,1]+conf_matrix[2,2]\n",
    "            conf_mat2[0,0],conf_mat2[0,1],conf_mat2[1,0],conf_mat2[1,1] = conf_matrix[1,1],conf_matrix[1,0]+conf_matrix[1,2],\\\n",
    "                                                                         conf_matrix[0,1]+conf_matrix[2,1],conf_matrix[0,0]+\\\n",
    "                                                                         conf_matrix[0,2]+conf_matrix[2,0]+conf_matrix[2,2]\n",
    "            conf_mat3[0,0],conf_mat3[0,1],conf_mat3[1,0],conf_mat3[1,1] = conf_matrix[2,2],conf_matrix[2,0]+conf_matrix[2,1],\\\n",
    "                                                                          conf_matrix[0,2]+conf_matrix[1,2],conf_matrix[0,0]+\\\n",
    "                                                                          conf_matrix[1,1]+conf_matrix[0,1]+conf_matrix[1,0]\n",
    "#             print(conf_mat3)\n",
    "            TS = (conf_mat3[0,0])/(conf_mat3[0,0]+conf_mat3[0,1]+conf_mat3[1,0])\n",
    "            FAR = (conf_matrix[0,1])/(conf_matrix[0,1]+conf_matrix[1,1])\n",
    "            accuracy = accuracy_score(Y_test, Y_test_predict)\n",
    "            sigmysigmo =(np.sum(conf_matrix,axis=1)[0]*np.sum(conf_matrix,axis=0)[0]+np.sum(conf_matrix,axis=1)[1]*np.sum(conf_matrix,axis=0)[1]\\\n",
    "                         +np.sum(conf_matrix,axis=1)[2]*np.sum(conf_matrix,axis=0)[2])\\\n",
    "                        /(len(Y_test)**2)\n",
    "            HSS = (accuracy-sigmysigmo)/(1-sigmysigmo)\n",
    "            sub_list =[err,scene,clf,scores.mean()*100,HSS,TS,FAR]\n",
    "            df_l.append(sub_list)\n",
    "            \n",
    "            \n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329bd7fe",
   "metadata": {},
   "source": [
    "## Performance Evaluation with spatial information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f659ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#### Calling Data\n",
    "crowd_data = pd.read_csv(r'/Volumes/One_Touch/Project/crowd_sourcing/crowd/5_person_grid(1).csv')\n",
    "crowd_data = crowd_data.iloc[:,1:]\n",
    "df = crowd_data.iloc[:,[0,1,2,3,6,7]]\n",
    "df_cols = list(df.columns)\n",
    "df.insert(loc = 1 ,column = 'Person_id', value = crowd_data['Person_id'].values)\n",
    "df_cols = list(df.columns)\n",
    "#### Adding errors or scenario generation\n",
    "import random\n",
    "scene = {'Intensity':[3] , 'Duration':[4], 'Inten_Dur':[3,4]}\n",
    "dlist = [1.0,2.0,3.0]\n",
    "perc_error = 30\n",
    "index = np.random.randint(0 , df.shape[0] , size = round(perc_error*df.shape[0]/100))\n",
    "df_err = df.values\n",
    "x = 'Inten_Dur'\n",
    "for j in range (len(scene[x])):\n",
    "    y = scene[x]\n",
    "    for i in index:\n",
    "        if df_err[i,y[j]] == 1:\n",
    "            dlist.remove(1)\n",
    "            df_err[i,y[j]] = random.choice(dlist)\n",
    "        elif df_err[i,y[j]] == 2:\n",
    "            dlist.remove(2)\n",
    "            df_err[i,y[j]] = random.choice(dlist)\n",
    "        else:\n",
    "            dlist.remove(3)\n",
    "            df_err[i,y[j]] = random.choice(dlist)\n",
    "        dlist = [1,2,3]\n",
    "err_df = pd.DataFrame(df_err,columns = df_cols)\n",
    "\n",
    "err_df['Target'] = err_df['Target'].astype('int')\n",
    "input_feats = ['Gauge_Id','Intensity_class','Duration_class','Storm Center']  #### Using spatial information as feature\n",
    "features = err_df[input_feats]\n",
    "target = 'Target'\n",
    "target_feats = err_df[target]\n",
    "##### Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(features, target_feats, test_size = 0.3,random_state =42)\n",
    "#Y_train = Y_train.astype('int32')\n",
    "\n",
    "#### Importing Libraries for Accuracy check\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "#### Importing Libraries For Model Fitting\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier      #### Random Forest\n",
    "from sklearn.linear_model import LogisticRegression      #### Logistic Regression\n",
    "\n",
    "#### Random Forest Ensemble Model\n",
    "\n",
    "print(\"Random Forest Results\")\n",
    "rnd_model = RandomForestClassifier(criterion='gini',random_state = 0)\n",
    "rnd_model.fit(X_train,Y_train)\n",
    "Y_train_predict = rnd_model.predict(X_train)\n",
    "Y_test_predict  = rnd_model.predict(X_test)\n",
    "print('Training accuracy got RF = ',accuracy_score(Y_train, Y_train_predict)*100,'%')\n",
    "print('Test accuracy for RF = ',accuracy_score(Y_test, Y_test_predict)*100,'%')\n",
    "scores = cross_val_score(rnd_model, X_train, Y_train, cv = 3, scoring='accuracy')\n",
    "print('Cross val accuracy for RF = ', scores.mean()*100,'%')\n",
    "print('Confusion Matrix for Random Forest: \\n\\n', confusion_matrix(Y_train, Y_train_predict))\n",
    "print('\\n############################################')\n",
    "\n",
    "\n",
    "#### Logistic Regression Classifier\n",
    "\n",
    "print(\"Logistic Regression Results\")\n",
    "model = LogisticRegression(multi_class = 'multinomial',random_state = 0,max_iter=1000)\n",
    "model.fit(X_train,Y_train)\n",
    "Y_train_predict = model.predict(X_train)\n",
    "Y_test_predict  = model.predict(X_test)\n",
    "print('Training accuracy for LG = ',accuracy_score(Y_train, Y_train_predict)*100,'%')\n",
    "print('Test accuracy for LG = ',accuracy_score(Y_test, Y_test_predict)*100,'%')\n",
    "scores = cross_val_score(model, X_train, Y_train, cv = 3, scoring='accuracy')\n",
    "print('Cross val accuracy for LG = ', scores.mean()*100,'%')\n",
    "print('Confusion Matrix for Logistic Regression: \\n\\n', confusion_matrix(Y_train, Y_train_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7146716",
   "metadata": {},
   "source": [
    "## Feature Importance For Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704ce4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "importances = rnd_model.feature_importances_\n",
    "feature_names = features.columns\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': ['Duration','Intensity'],\n",
    "    'importance': importances\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Display feature importances\n",
    "print(\"Feature Importances:\\n\", feature_importance_df)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance_df)\n",
    "plt.title('Feature Importances')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RainyDay_Env",
   "language": "python",
   "name": "rainyday_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
